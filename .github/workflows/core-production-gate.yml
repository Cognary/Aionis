name: Core Production Gate

on:
  workflow_dispatch:
    inputs:
      run_perf:
        description: "Run perf benchmark checks"
        required: false
        default: true
        type: boolean
      recall_p95_max_ms:
        description: "Recall p95 threshold (ms)"
        required: false
        default: "1500"
        type: string
      write_p95_max_ms:
        description: "Write p95 threshold (ms)"
        required: false
        default: "1000"
        type: string
      error_rate_max:
        description: "Max case error rate (0~1)"
        required: false
        default: "0.05"
        type: string
      backend_parity_history_enforce:
        description: "Fail if backend parity history thresholds are violated"
        required: false
        default: false
        type: boolean
      backend_parity_history_min_runs:
        description: "Minimum backend parity history runs required"
        required: false
        default: "2"
        type: string
      backend_parity_history_max_failed_runs:
        description: "Maximum failed runs allowed in backend parity history"
        required: false
        default: "0"
        type: string
      backend_parity_history_max_latest_failed_samples:
        description: "Maximum latest failed samples allowed in backend parity history"
        required: false
        default: "0"
        type: string
      backend_parity_history_max_persist_total_avg_delta:
        description: "Maximum latest-vs-previous delta for persist_total_avg"
        required: false
        default: "2.0"
        type: string
      backend_parity_history_max_dropped_nodes_max_delta:
        description: "Maximum latest-vs-previous delta for dropped_nodes_max"
        required: false
        default: "8"
        type: string
      backend_parity_history_enforce_drift:
        description: "Promote drift delta violations to fail (even when history enforce is false)"
        required: false
        default: true
        type: boolean
      backend_parity_history_calibration_enabled:
        description: "Auto-calibrate drift delta thresholds from recent successful backend-parity history window"
        required: false
        default: true
        type: boolean
      backend_parity_history_calibration_window_runs:
        description: "Calibration window size (runs, excluding latest sample)"
        required: false
        default: "8"
        type: string
      backend_parity_history_calibration_percentile:
        description: "Calibration percentile for delta bands (e.g. 95)"
        required: false
        default: "95"
        type: string
      backend_parity_history_calibration_margin_persist_total_avg_delta:
        description: "Calibration margin added to persist_total_avg delta percentile"
        required: false
        default: "0.5"
        type: string
      backend_parity_history_calibration_margin_dropped_nodes_max_delta:
        description: "Calibration margin added to dropped_nodes_max delta percentile"
        required: false
        default: "2"
        type: string
  push:
    branches: ["main"]
    paths:
      - "src/**"
      - "scripts/**"
      - "docs/**"
      - "package.json"
      - ".github/workflows/core-production-gate.yml"

permissions:
  contents: read
  actions: read

concurrency:
  group: core-production-gate-${{ github.ref }}
  cancel-in-progress: true

jobs:
  core-gate:
    runs-on: ubuntu-latest
    timeout-minutes: 90
    env:
      PORT: "3001"
      BASE_URL: http://localhost:3001
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Node
        uses: actions/setup-node@v4
        with:
          node-version: 20
          cache: npm

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install deps
        run: npm ci

      - name: Prepare env
        shell: bash
        run: |
          set -euo pipefail
          cp .env.example .env
          npm run -s env:throughput:benchmark
          {
            echo "APP_ENV=ci"
            echo "PORT=3001"
            echo "MEMORY_AUTH_MODE=off"
            echo "ADMIN_TOKEN=ci-admin-token"
            echo "DATABASE_URL=postgres://aionis:aionis@127.0.0.1:5432/aionis_memory"
            echo "EMBEDDING_PROVIDER=fake"
            echo "RATE_LIMIT_BYPASS_LOOPBACK=false"
            echo "MEMORY_RECALL_PROFILE=strict_edges"
          } >> .env

      - name: Start stack
        run: docker compose up -d --build

      - name: Wait API health
        shell: bash
        run: |
          set -euo pipefail
          ok=0
          for _ in {1..120}; do
            if curl -fsS "http://localhost:3001/health" >/dev/null 2>&1; then
              ok=1
              break
            fi
            sleep 1
          done
          if [[ "${ok}" -ne 1 ]]; then
            echo "API not healthy on localhost:3001" >&2
            exit 1
          fi

      - name: Capability API probes
        shell: bash
        env:
          AIONIS_BASE_URL: http://localhost:3001
          ADMIN_TOKEN: ci-admin-token
          CAPABILITY_PROBE_OUTPUT: /tmp/core_gate_capability_api_probe.json
          CAPABILITY_PROBE_SCOPE: default
          CAPABILITY_PROBE_TENANT_ID: default
          CAPABILITY_PROBE_INCLUDE_SHADOW_SOFT_DEGRADE: auto
        run: |
          set -euo pipefail
          bash scripts/ci/capability-api-probes.sh
          cat /tmp/core_gate_capability_api_probe.json || true

      - name: Policy + planner API probes
        shell: bash
        env:
          AIONIS_BASE_URL: http://localhost:3001
          POLICY_PLANNER_PROBE_SCOPE: default
          POLICY_PLANNER_PROBE_TENANT_ID: default
        run: |
          set -euo pipefail
          bash scripts/ci/policy-planner-api-probes.sh >/tmp/core_gate_policy_planner_probe.json
          cat /tmp/core_gate_policy_planner_probe.json || true

      - name: Run core production gate
        shell: bash
        run: |
          set -euo pipefail
          RUN_PERF_INPUT="${{ github.event_name == 'workflow_dispatch' && github.event.inputs.run_perf || 'true' }}"
          RECALL_P95_INPUT="${{ github.event_name == 'workflow_dispatch' && github.event.inputs.recall_p95_max_ms || '1500' }}"
          WRITE_P95_INPUT="${{ github.event_name == 'workflow_dispatch' && github.event.inputs.write_p95_max_ms || '1000' }}"
          ERROR_RATE_INPUT="${{ github.event_name == 'workflow_dispatch' && github.event.inputs.error_rate_max || '0.05' }}"
          npm run -s gate:core:prod -- \
            --base-url "http://localhost:3001" \
            --scope default \
            --run-perf "${RUN_PERF_INPUT}" \
            --recall-p95-max-ms "${RECALL_P95_INPUT}" \
            --write-p95-max-ms "${WRITE_P95_INPUT}" \
            --error-rate-max "${ERROR_RATE_INPUT}"

      - name: Run governance weekly report gate
        shell: bash
        run: |
          set -euo pipefail
          out_dir="artifacts/governance/ci/${GITHUB_RUN_ID}_${GITHUB_RUN_ATTEMPT}"
          npm run -s job:governance-weekly-report -- \
            --scope default \
            --window-hours 168 \
            --strict-warnings \
            --out-dir "${out_dir}"

      - name: Backend parity telemetry history check
        if: always()
        shell: bash
        env:
          GH_TOKEN: ${{ github.token }}
        run: |
          set -euo pipefail

          ENFORCE_INPUT="${{ github.event_name == 'workflow_dispatch' && github.event.inputs.backend_parity_history_enforce || 'false' }}"
          MIN_RUNS_INPUT="${{ github.event_name == 'workflow_dispatch' && github.event.inputs.backend_parity_history_min_runs || '2' }}"
          MAX_FAILED_RUNS_INPUT="${{ github.event_name == 'workflow_dispatch' && github.event.inputs.backend_parity_history_max_failed_runs || '0' }}"
          MAX_LATEST_FAILED_SAMPLES_INPUT="${{ github.event_name == 'workflow_dispatch' && github.event.inputs.backend_parity_history_max_latest_failed_samples || '0' }}"
          MAX_PERSIST_TOTAL_AVG_DELTA_INPUT="${{ github.event_name == 'workflow_dispatch' && github.event.inputs.backend_parity_history_max_persist_total_avg_delta || '2.0' }}"
          MAX_DROPPED_NODES_MAX_DELTA_INPUT="${{ github.event_name == 'workflow_dispatch' && github.event.inputs.backend_parity_history_max_dropped_nodes_max_delta || '8' }}"
          ENFORCE_DRIFT_INPUT="${{ github.event_name == 'workflow_dispatch' && github.event.inputs.backend_parity_history_enforce_drift || 'true' }}"
          CALIBRATION_ENABLED_INPUT="${{ github.event_name == 'workflow_dispatch' && github.event.inputs.backend_parity_history_calibration_enabled || 'true' }}"
          CALIBRATION_WINDOW_RUNS_INPUT="${{ github.event_name == 'workflow_dispatch' && github.event.inputs.backend_parity_history_calibration_window_runs || '8' }}"
          CALIBRATION_PERCENTILE_INPUT="${{ github.event_name == 'workflow_dispatch' && github.event.inputs.backend_parity_history_calibration_percentile || '95' }}"
          CALIBRATION_MARGIN_PERSIST_INPUT="${{ github.event_name == 'workflow_dispatch' && github.event.inputs.backend_parity_history_calibration_margin_persist_total_avg_delta || '0.5' }}"
          CALIBRATION_MARGIN_DROPPED_INPUT="${{ github.event_name == 'workflow_dispatch' && github.event.inputs.backend_parity_history_calibration_margin_dropped_nodes_max_delta || '2' }}"

          enforce="$(printf '%s' "${ENFORCE_INPUT}" | tr '[:upper:]' '[:lower:]')"
          if [[ "${enforce}" != "true" ]]; then enforce="false"; fi
          enforce_drift="$(printf '%s' "${ENFORCE_DRIFT_INPUT}" | tr '[:upper:]' '[:lower:]')"
          if [[ "${enforce_drift}" != "true" ]]; then enforce_drift="false"; fi
          calibration_enabled="$(printf '%s' "${CALIBRATION_ENABLED_INPUT}" | tr '[:upper:]' '[:lower:]')"
          if [[ "${calibration_enabled}" != "true" ]]; then calibration_enabled="false"; fi

          min_runs="${MIN_RUNS_INPUT}"
          max_failed_runs="${MAX_FAILED_RUNS_INPUT}"
          max_latest_failed_samples="${MAX_LATEST_FAILED_SAMPLES_INPUT}"
          max_persist_total_avg_delta="${MAX_PERSIST_TOTAL_AVG_DELTA_INPUT}"
          max_dropped_nodes_max_delta="${MAX_DROPPED_NODES_MAX_DELTA_INPUT}"
          calibration_window_runs="${CALIBRATION_WINDOW_RUNS_INPUT}"
          calibration_percentile="${CALIBRATION_PERCENTILE_INPUT}"
          calibration_margin_persist_total_avg_delta="${CALIBRATION_MARGIN_PERSIST_INPUT}"
          calibration_margin_dropped_nodes_max_delta="${CALIBRATION_MARGIN_DROPPED_INPUT}"
          [[ "${min_runs}" =~ ^[0-9]+$ ]] || min_runs="2"
          [[ "${max_failed_runs}" =~ ^[0-9]+$ ]] || max_failed_runs="0"
          [[ "${max_latest_failed_samples}" =~ ^[0-9]+$ ]] || max_latest_failed_samples="0"
          [[ "${max_persist_total_avg_delta}" =~ ^[0-9]+([.][0-9]+)?$ ]] || max_persist_total_avg_delta="2.0"
          [[ "${max_dropped_nodes_max_delta}" =~ ^[0-9]+([.][0-9]+)?$ ]] || max_dropped_nodes_max_delta="8"
          [[ "${calibration_window_runs}" =~ ^[0-9]+$ ]] || calibration_window_runs="8"
          [[ "${calibration_percentile}" =~ ^[0-9]+([.][0-9]+)?$ ]] || calibration_percentile="95"
          [[ "${calibration_margin_persist_total_avg_delta}" =~ ^[0-9]+([.][0-9]+)?$ ]] || calibration_margin_persist_total_avg_delta="0.5"
          [[ "${calibration_margin_dropped_nodes_max_delta}" =~ ^[0-9]+([.][0-9]+)?$ ]] || calibration_margin_dropped_nodes_max_delta="2"

          out_dir="artifacts/core_gate/backend_parity_history"
          mkdir -p "${out_dir}"
          check_file="${out_dir}/check.json"
          reasons_json='[]'
          status="ok"
          source_run_id=""
          source_head_sha=""
          runs_total=0
          runs_with_failures=0
          latest_failed_samples=0
          latest_persist_total_avg="null"
          previous_persist_total_avg="null"
          persist_total_avg_delta="null"
          latest_dropped_nodes_max="null"
          previous_dropped_nodes_max="null"
          dropped_nodes_max_delta="null"
          effective_max_persist_total_avg_delta="${max_persist_total_avg_delta}"
          effective_max_dropped_nodes_max_delta="${max_dropped_nodes_max_delta}"
          calibration_json='null'
          drift_violations_count=0
          history_summary_file=""

          add_reason() {
            local reason="$1"
            reasons_json="$(jq -c --arg reason "${reason}" '. + [$reason]' <<<"${reasons_json}")"
          }

          if latest_runs_json="$(gh run list --workflow "Backend Parity Smoke" --branch main --limit 20 --json databaseId,conclusion,headSha,createdAt 2>/tmp/core_gate_backend_parity_history_gh_list.err)"; then
            source_run_id="$(jq -r '[.[] | select(.conclusion=="success")] | first | .databaseId // empty' <<<"${latest_runs_json}")"
            source_head_sha="$(jq -r '[.[] | select(.conclusion=="success")] | first | .headSha // empty' <<<"${latest_runs_json}")"
          else
            add_reason "gh_run_list_failed"
          fi

          if [[ -z "${source_run_id}" ]]; then
            add_reason "no_successful_backend_parity_run_found"
          else
            dl_dir="$(mktemp -d)"
            if gh run download "${source_run_id}" -n backend-parity-rollup -D "${dl_dir}" >/tmp/core_gate_backend_parity_history_gh_download.log 2>&1; then
              history_summary_file="$(find "${dl_dir}" -type f -path '*/history/summary.json' | head -n 1 || true)"
              if [[ -n "${history_summary_file}" && -f "${history_summary_file}" ]]; then
                cp "${history_summary_file}" "${out_dir}/history_summary_run_${source_run_id}.json"
                runs_total="$(jq -r '.runs_total // 0' "${history_summary_file}")"
                runs_with_failures="$(jq -r '.runs_with_failures // 0' "${history_summary_file}")"
                latest_failed_samples="$(jq -r '.latest.failed_samples // 0' "${history_summary_file}")"
                latest_persist_total_avg="$(jq -r '.latest.persist_total_avg // "null"' "${history_summary_file}")"
                previous_persist_total_avg="$(jq -r 'if (.series | length) >= 2 then (.series[-2].persist_total_avg // "null") else "null" end' "${history_summary_file}")"
                persist_total_avg_delta="$(jq -r '
                  def num_or_null(v): if (v | type) == "number" then v else null end;
                  if (.series | length) >= 2 then
                    (num_or_null(.latest.persist_total_avg) as $l
                      | num_or_null(.series[-2].persist_total_avg) as $p
                      | if ($l != null and $p != null) then ($l - $p) else null end)
                  else null end // "null"
                ' "${history_summary_file}")"
                latest_dropped_nodes_max="$(jq -r '.latest.dropped_nodes_max // "null"' "${history_summary_file}")"
                previous_dropped_nodes_max="$(jq -r 'if (.series | length) >= 2 then (.series[-2].dropped_nodes_max // "null") else "null" end' "${history_summary_file}")"
                dropped_nodes_max_delta="$(jq -r '
                  def num_or_null(v): if (v | type) == "number" then v else null end;
                  if (.series | length) >= 2 then
                    (num_or_null(.latest.dropped_nodes_max) as $l
                      | num_or_null(.series[-2].dropped_nodes_max) as $p
                      | if ($l != null and $p != null) then ($l - $p) else null end)
                  else null end // "null"
                ' "${history_summary_file}")"
              else
                add_reason "history_summary_missing_in_backend_parity_rollup_artifact"
              fi
            else
              add_reason "gh_run_download_backend_parity_rollup_failed"
            fi
            rm -rf "${dl_dir}" || true
          fi

          if [[ "${runs_total}" -lt "${min_runs}" ]]; then
            add_reason "runs_total_below_min_threshold"
          fi
          if [[ "${runs_with_failures}" -gt "${max_failed_runs}" ]]; then
            add_reason "runs_with_failures_above_threshold"
          fi
          if [[ "${latest_failed_samples}" -gt "${max_latest_failed_samples}" ]]; then
            add_reason "latest_failed_samples_above_threshold"
          fi

          compare_float_gt() {
            local left="$1"
            local right="$2"
            awk -v a="${left}" -v b="${right}" 'BEGIN { exit !(a>b) }'
          }

          if [[ "${calibration_enabled}" == "true" ]] && [[ -n "${history_summary_file}" && -f "${history_summary_file}" ]]; then
            calibration_json="$(jq -c \
              --argjson window_runs "${calibration_window_runs}" \
              --argjson percentile "${calibration_percentile}" \
              --argjson margin_persist "${calibration_margin_persist_total_avg_delta}" \
              --argjson margin_dropped "${calibration_margin_dropped_nodes_max_delta}" \
              '
              def num_or_null(v): if (v | type) == "number" then v else null end;
              def percentile(values; p):
                (values | map(select(. != null)) | sort) as $vals
                | if ($vals | length) == 0 then null
                  else
                    (($vals | length) as $n
                      | ((((p / 100) * $n) | ceil) - 1) as $idx
                      | $vals[
                          if $idx < 0 then 0
                          elif $idx >= $n then ($n - 1)
                          else $idx
                          end
                        ])
                  end;
              (.series // []) as $series
              | ($series | if length > 1 then .[0:-1] else [] end) as $baseline_all
              | ($baseline_all
                  | if ($window_runs > 0 and (length > $window_runs)) then .[(length - $window_runs):] else . end
                ) as $baseline
              | (
                  [range(1; ($baseline | length)) as $i
                    | (num_or_null($baseline[$i].persist_total_avg) as $cur
                      | num_or_null($baseline[$i-1].persist_total_avg) as $prev
                      | if ($cur != null and $prev != null) then ($cur - $prev) else null end)
                  ]
                  | map(select(. != null))
                ) as $persist_deltas
              | (
                  [range(1; ($baseline | length)) as $i
                    | (num_or_null($baseline[$i].dropped_nodes_max) as $cur
                      | num_or_null($baseline[$i-1].dropped_nodes_max) as $prev
                      | if ($cur != null and $prev != null) then ($cur - $prev) else null end)
                  ]
                  | map(select(. != null))
                ) as $dropped_deltas
              | (percentile($persist_deltas; $percentile)) as $persist_pctl
              | (percentile($dropped_deltas; $percentile)) as $dropped_pctl
              | {
                  enabled: true,
                  window_runs_requested: $window_runs,
                  percentile: $percentile,
                  baseline_runs: ($baseline | length),
                  baseline_delta_pairs: {
                    persist_total_avg: ($persist_deltas | length),
                    dropped_nodes_max: ($dropped_deltas | length)
                  },
                  percentile_delta: {
                    persist_total_avg: $persist_pctl,
                    dropped_nodes_max: $dropped_pctl
                  },
                  margins: {
                    persist_total_avg_delta: $margin_persist,
                    dropped_nodes_max_delta: $margin_dropped
                  },
                  suggested: {
                    max_persist_total_avg_delta: (if $persist_pctl == null then null else ($persist_pctl + $margin_persist) end),
                    max_dropped_nodes_max_delta: (if $dropped_pctl == null then null else ($dropped_pctl + $margin_dropped) end)
                  }
                }
              ' "${history_summary_file}")"

            suggested_persist_total_avg_delta="$(jq -r '.suggested.max_persist_total_avg_delta // "null"' <<<"${calibration_json}")"
            suggested_dropped_nodes_max_delta="$(jq -r '.suggested.max_dropped_nodes_max_delta // "null"' <<<"${calibration_json}")"

            if [[ "${suggested_persist_total_avg_delta}" != "null" ]] \
              && compare_float_gt "${suggested_persist_total_avg_delta}" "${effective_max_persist_total_avg_delta}"; then
              effective_max_persist_total_avg_delta="${suggested_persist_total_avg_delta}"
            fi
            if [[ "${suggested_dropped_nodes_max_delta}" != "null" ]] \
              && compare_float_gt "${suggested_dropped_nodes_max_delta}" "${effective_max_dropped_nodes_max_delta}"; then
              effective_max_dropped_nodes_max_delta="${suggested_dropped_nodes_max_delta}"
            fi
          fi

          if [[ "${persist_total_avg_delta}" != "null" ]] && compare_float_gt "${persist_total_avg_delta}" "${effective_max_persist_total_avg_delta}"; then
            add_reason "persist_total_avg_delta_above_threshold"
          fi
          if [[ "${dropped_nodes_max_delta}" != "null" ]] && compare_float_gt "${dropped_nodes_max_delta}" "${effective_max_dropped_nodes_max_delta}"; then
            add_reason "dropped_nodes_max_delta_above_threshold"
          fi

          reasons_count="$(jq 'length' <<<"${reasons_json}")"
          drift_violations_count="$(jq -r '
            [
              .[]
              | select(. == "persist_total_avg_delta_above_threshold" or . == "dropped_nodes_max_delta_above_threshold")
            ] | length
          ' <<<"${reasons_json}")"
          if [[ "${reasons_count}" -gt 0 ]]; then
            status="warn"
            if [[ "${enforce}" == "true" ]]; then
              status="fail"
            elif [[ "${enforce_drift}" == "true" && "${drift_violations_count}" -gt 0 ]]; then
              status="fail"
            fi
          fi

          jq -n \
            --arg status "${status}" \
            --argjson enforce "${enforce}" \
            --argjson enforce_drift "${enforce_drift}" \
            --argjson calibration_enabled "${calibration_enabled}" \
            --arg source_run_id "${source_run_id}" \
            --arg source_head_sha "${source_head_sha}" \
            --argjson runs_total "${runs_total}" \
            --argjson runs_with_failures "${runs_with_failures}" \
            --argjson latest_failed_samples "${latest_failed_samples}" \
            --argjson min_runs "${min_runs}" \
            --argjson max_failed_runs "${max_failed_runs}" \
            --argjson max_latest_failed_samples "${max_latest_failed_samples}" \
            --argjson max_persist_total_avg_delta "${max_persist_total_avg_delta}" \
            --argjson max_dropped_nodes_max_delta "${max_dropped_nodes_max_delta}" \
            --argjson effective_max_persist_total_avg_delta "${effective_max_persist_total_avg_delta}" \
            --argjson effective_max_dropped_nodes_max_delta "${effective_max_dropped_nodes_max_delta}" \
            --argjson calibration_window_runs "${calibration_window_runs}" \
            --argjson calibration_percentile "${calibration_percentile}" \
            --argjson calibration_margin_persist_total_avg_delta "${calibration_margin_persist_total_avg_delta}" \
            --argjson calibration_margin_dropped_nodes_max_delta "${calibration_margin_dropped_nodes_max_delta}" \
            --argjson drift_violations_count "${drift_violations_count}" \
            --argjson calibration "${calibration_json}" \
            --argjson reasons "${reasons_json}" \
            --arg latest_persist_total_avg "${latest_persist_total_avg}" \
            --arg previous_persist_total_avg "${previous_persist_total_avg}" \
            --arg persist_total_avg_delta "${persist_total_avg_delta}" \
            --arg latest_dropped_nodes_max "${latest_dropped_nodes_max}" \
            --arg previous_dropped_nodes_max "${previous_dropped_nodes_max}" \
            --arg dropped_nodes_max_delta "${dropped_nodes_max_delta}" \
            '{
              status: $status,
              enforce: $enforce,
              enforce_drift: $enforce_drift,
              source_run_id: (if $source_run_id == "" then null else $source_run_id end),
              source_head_sha: (if $source_head_sha == "" then null else $source_head_sha end),
              thresholds: {
                min_runs: $min_runs,
                max_failed_runs: $max_failed_runs,
                max_latest_failed_samples: $max_latest_failed_samples,
                max_persist_total_avg_delta: $max_persist_total_avg_delta,
                max_dropped_nodes_max_delta: $max_dropped_nodes_max_delta,
                effective_max_persist_total_avg_delta: $effective_max_persist_total_avg_delta,
                effective_max_dropped_nodes_max_delta: $effective_max_dropped_nodes_max_delta
              },
              calibration: {
                enabled: $calibration_enabled,
                requested: {
                  window_runs: $calibration_window_runs,
                  percentile: $calibration_percentile,
                  margin_persist_total_avg_delta: $calibration_margin_persist_total_avg_delta,
                  margin_dropped_nodes_max_delta: $calibration_margin_dropped_nodes_max_delta
                },
                observed: $calibration
              },
              observed: {
                runs_total: $runs_total,
                runs_with_failures: $runs_with_failures,
                latest_failed_samples: $latest_failed_samples,
                latest_persist_total_avg: (if $latest_persist_total_avg == "null" then null else ($latest_persist_total_avg | tonumber) end),
                previous_persist_total_avg: (if $previous_persist_total_avg == "null" then null else ($previous_persist_total_avg | tonumber) end),
                persist_total_avg_delta: (if $persist_total_avg_delta == "null" then null else ($persist_total_avg_delta | tonumber) end),
                latest_dropped_nodes_max: (if $latest_dropped_nodes_max == "null" then null else ($latest_dropped_nodes_max | tonumber) end),
                previous_dropped_nodes_max: (if $previous_dropped_nodes_max == "null" then null else ($previous_dropped_nodes_max | tonumber) end),
                dropped_nodes_max_delta: (if $dropped_nodes_max_delta == "null" then null else ($dropped_nodes_max_delta | tonumber) end),
                drift_violations_count: $drift_violations_count
              },
              reasons: $reasons
            }' > "${check_file}"

          cat "${check_file}"

          if [[ "${status}" == "fail" ]]; then
            echo "backend parity telemetry history thresholds violated in enforce/enforce_drift mode" >&2
            exit 1
          fi

      - name: Publish summary
        if: always()
        shell: bash
        run: |
          set -euo pipefail
          summary_file="$(find artifacts/core_gate -type f -name summary.json | sort | tail -n 1 || true)"
          governance_summary_file="$(find artifacts/governance -type f -name summary.json | sort | tail -n 1 || true)"
          backend_parity_history_check_file="artifacts/core_gate/backend_parity_history/check.json"
          backend_parity_history_summary_file="$(find artifacts/core_gate/backend_parity_history -type f -name 'history_summary_run_*.json' | sort | tail -n 1 || true)"
          {
            echo "## Core Production Gate"
            echo
            if [[ -n "${summary_file}" && -f "${summary_file}" ]]; then
              echo "summary: \`${summary_file}\`"
              echo
              jq '.' "${summary_file}"
            else
              echo "summary not found"
            fi
            echo
            echo "## Governance Weekly Report Gate"
            echo
            if [[ -n "${governance_summary_file}" && -f "${governance_summary_file}" ]]; then
              echo "summary: \`${governance_summary_file}\`"
              echo
              jq '.' "${governance_summary_file}"
            else
              echo "summary not found"
            fi
            echo
            echo "## Backend Parity Telemetry History"
            echo
            if [[ -f "${backend_parity_history_check_file}" ]]; then
              echo "check: \`${backend_parity_history_check_file}\`"
              echo
              jq '.' "${backend_parity_history_check_file}"
            else
              echo "check not found"
            fi
            echo
            if [[ -n "${backend_parity_history_summary_file}" && -f "${backend_parity_history_summary_file}" ]]; then
              echo "history summary: \`${backend_parity_history_summary_file}\`"
              echo
              jq '{ok, runs_total, runs_with_failures, latest, stats, failed_runs}' "${backend_parity_history_summary_file}"
            else
              echo "history summary not found"
            fi
          } >> "${GITHUB_STEP_SUMMARY}"

      - name: Upload artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: core-production-gate-artifacts
          path: |
            artifacts/core_gate/
            artifacts/governance/
          retention-days: 14
          if-no-files-found: warn

      - name: Capture diagnostics on failure
        if: failure()
        shell: bash
        run: |
          set +e
          mkdir -p /tmp/core_gate_diag
          cp /tmp/core_gate_capability_api_probe.json /tmp/core_gate_diag/capability_api_probe.json 2>/dev/null || true
          cp /tmp/core_gate_policy_planner_probe.json /tmp/core_gate_diag/policy_planner_api_probe.json 2>/dev/null || true
          cp artifacts/core_gate/backend_parity_history/check.json /tmp/core_gate_diag/backend_parity_history_check.json 2>/dev/null || true
          cp artifacts/core_gate/backend_parity_history/history_summary_run_*.json /tmp/core_gate_diag/ 2>/dev/null || true
          find artifacts/core_gate -type f -maxdepth 3 2>/dev/null | sort > /tmp/core_gate_diag/files.txt || true
          summary_file="$(find artifacts/core_gate -type f -name summary.json | sort | tail -n 1 || true)"
          if [[ -n "${summary_file}" && -f "${summary_file}" ]]; then
            jq '{ok, fail_reasons, steps}' "${summary_file}" > /tmp/core_gate_diag/summary_excerpt.json || true
          fi
          docker compose ps > /tmp/core_gate_diag/compose_ps.txt || true
          docker compose logs --no-color > /tmp/core_gate_diag/compose_logs.txt || true

      - name: Upload diagnostics
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: core-production-gate-diagnostics
          path: /tmp/core_gate_diag/
          retention-days: 14
          if-no-files-found: warn

      - name: Stop stack
        if: always()
        shell: bash
        run: |
          set +e
          if [[ -f docker-compose.yml ]]; then
            docker compose down -v
          else
            echo "docker-compose.yml not found, skip compose down"
          fi
