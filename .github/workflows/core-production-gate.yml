name: Core Production Gate

on:
  workflow_dispatch:
    inputs:
      run_perf:
        description: "Run perf benchmark checks"
        required: false
        default: true
        type: boolean
      recall_p95_max_ms:
        description: "Recall p95 threshold (ms)"
        required: false
        default: "1500"
        type: string
      write_p95_max_ms:
        description: "Write p95 threshold (ms)"
        required: false
        default: "1000"
        type: string
      error_rate_max:
        description: "Max case error rate (0~1)"
        required: false
        default: "0.05"
        type: string
      backend_parity_history_enforce:
        description: "Fail if backend parity history thresholds are violated"
        required: false
        default: false
        type: boolean
      backend_parity_history_min_runs:
        description: "Minimum backend parity history runs required"
        required: false
        default: "2"
        type: string
      backend_parity_history_max_failed_runs:
        description: "Maximum failed runs allowed in backend parity history"
        required: false
        default: "0"
        type: string
      backend_parity_history_max_latest_failed_samples:
        description: "Maximum latest failed samples allowed in backend parity history"
        required: false
        default: "0"
        type: string
      backend_parity_history_max_persist_total_avg_delta:
        description: "Maximum latest-vs-previous delta for persist_total_avg"
        required: false
        default: "2.0"
        type: string
      backend_parity_history_max_dropped_nodes_max_delta:
        description: "Maximum latest-vs-previous delta for dropped_nodes_max"
        required: false
        default: "8"
        type: string
  push:
    branches: ["main"]
    paths:
      - "src/**"
      - "scripts/**"
      - "docs/**"
      - "package.json"
      - ".github/workflows/core-production-gate.yml"

permissions:
  contents: read
  actions: read

concurrency:
  group: core-production-gate-${{ github.ref }}
  cancel-in-progress: true

jobs:
  core-gate:
    runs-on: ubuntu-latest
    timeout-minutes: 90
    env:
      PORT: "3001"
      BASE_URL: http://localhost:3001
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Node
        uses: actions/setup-node@v4
        with:
          node-version: 20
          cache: npm

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install deps
        run: npm ci

      - name: Prepare env
        shell: bash
        run: |
          set -euo pipefail
          cp .env.example .env
          npm run -s env:throughput:benchmark
          {
            echo "APP_ENV=ci"
            echo "PORT=3001"
            echo "MEMORY_AUTH_MODE=off"
            echo "ADMIN_TOKEN=ci-admin-token"
            echo "DATABASE_URL=postgres://aionis:aionis@127.0.0.1:5432/aionis_memory"
            echo "EMBEDDING_PROVIDER=fake"
            echo "RATE_LIMIT_BYPASS_LOOPBACK=false"
            echo "MEMORY_RECALL_PROFILE=strict_edges"
          } >> .env

      - name: Start stack
        run: docker compose up -d --build

      - name: Wait API health
        shell: bash
        run: |
          set -euo pipefail
          ok=0
          for _ in {1..120}; do
            if curl -fsS "http://localhost:3001/health" >/dev/null 2>&1; then
              ok=1
              break
            fi
            sleep 1
          done
          if [[ "${ok}" -ne 1 ]]; then
            echo "API not healthy on localhost:3001" >&2
            exit 1
          fi

      - name: Capability API probes
        shell: bash
        env:
          AIONIS_BASE_URL: http://localhost:3001
          ADMIN_TOKEN: ci-admin-token
          CAPABILITY_PROBE_OUTPUT: /tmp/core_gate_capability_api_probe.json
          CAPABILITY_PROBE_SCOPE: default
          CAPABILITY_PROBE_TENANT_ID: default
          CAPABILITY_PROBE_INCLUDE_SHADOW_SOFT_DEGRADE: auto
        run: |
          set -euo pipefail
          bash scripts/ci/capability-api-probes.sh
          cat /tmp/core_gate_capability_api_probe.json || true

      - name: Policy + planner API probes
        shell: bash
        env:
          AIONIS_BASE_URL: http://localhost:3001
          POLICY_PLANNER_PROBE_SCOPE: default
          POLICY_PLANNER_PROBE_TENANT_ID: default
        run: |
          set -euo pipefail
          bash scripts/ci/policy-planner-api-probes.sh >/tmp/core_gate_policy_planner_probe.json
          cat /tmp/core_gate_policy_planner_probe.json || true

      - name: Run core production gate
        shell: bash
        run: |
          set -euo pipefail
          RUN_PERF_INPUT="${{ github.event_name == 'workflow_dispatch' && github.event.inputs.run_perf || 'true' }}"
          RECALL_P95_INPUT="${{ github.event_name == 'workflow_dispatch' && github.event.inputs.recall_p95_max_ms || '1500' }}"
          WRITE_P95_INPUT="${{ github.event_name == 'workflow_dispatch' && github.event.inputs.write_p95_max_ms || '1000' }}"
          ERROR_RATE_INPUT="${{ github.event_name == 'workflow_dispatch' && github.event.inputs.error_rate_max || '0.05' }}"
          npm run -s gate:core:prod -- \
            --base-url "http://localhost:3001" \
            --scope default \
            --run-perf "${RUN_PERF_INPUT}" \
            --recall-p95-max-ms "${RECALL_P95_INPUT}" \
            --write-p95-max-ms "${WRITE_P95_INPUT}" \
            --error-rate-max "${ERROR_RATE_INPUT}"

      - name: Run governance weekly report gate
        shell: bash
        run: |
          set -euo pipefail
          out_dir="artifacts/governance/ci/${GITHUB_RUN_ID}_${GITHUB_RUN_ATTEMPT}"
          npm run -s job:governance-weekly-report -- \
            --scope default \
            --window-hours 168 \
            --strict-warnings \
            --out-dir "${out_dir}"

      - name: Backend parity telemetry history check
        if: always()
        shell: bash
        env:
          GH_TOKEN: ${{ github.token }}
        run: |
          set -euo pipefail

          ENFORCE_INPUT="${{ github.event_name == 'workflow_dispatch' && github.event.inputs.backend_parity_history_enforce || 'false' }}"
          MIN_RUNS_INPUT="${{ github.event_name == 'workflow_dispatch' && github.event.inputs.backend_parity_history_min_runs || '2' }}"
          MAX_FAILED_RUNS_INPUT="${{ github.event_name == 'workflow_dispatch' && github.event.inputs.backend_parity_history_max_failed_runs || '0' }}"
          MAX_LATEST_FAILED_SAMPLES_INPUT="${{ github.event_name == 'workflow_dispatch' && github.event.inputs.backend_parity_history_max_latest_failed_samples || '0' }}"
          MAX_PERSIST_TOTAL_AVG_DELTA_INPUT="${{ github.event_name == 'workflow_dispatch' && github.event.inputs.backend_parity_history_max_persist_total_avg_delta || '2.0' }}"
          MAX_DROPPED_NODES_MAX_DELTA_INPUT="${{ github.event_name == 'workflow_dispatch' && github.event.inputs.backend_parity_history_max_dropped_nodes_max_delta || '8' }}"

          enforce="$(printf '%s' "${ENFORCE_INPUT}" | tr '[:upper:]' '[:lower:]')"
          if [[ "${enforce}" != "true" ]]; then enforce="false"; fi

          min_runs="${MIN_RUNS_INPUT}"
          max_failed_runs="${MAX_FAILED_RUNS_INPUT}"
          max_latest_failed_samples="${MAX_LATEST_FAILED_SAMPLES_INPUT}"
          max_persist_total_avg_delta="${MAX_PERSIST_TOTAL_AVG_DELTA_INPUT}"
          max_dropped_nodes_max_delta="${MAX_DROPPED_NODES_MAX_DELTA_INPUT}"
          [[ "${min_runs}" =~ ^[0-9]+$ ]] || min_runs="2"
          [[ "${max_failed_runs}" =~ ^[0-9]+$ ]] || max_failed_runs="0"
          [[ "${max_latest_failed_samples}" =~ ^[0-9]+$ ]] || max_latest_failed_samples="0"
          [[ "${max_persist_total_avg_delta}" =~ ^[0-9]+([.][0-9]+)?$ ]] || max_persist_total_avg_delta="2.0"
          [[ "${max_dropped_nodes_max_delta}" =~ ^[0-9]+([.][0-9]+)?$ ]] || max_dropped_nodes_max_delta="8"

          out_dir="artifacts/core_gate/backend_parity_history"
          mkdir -p "${out_dir}"
          check_file="${out_dir}/check.json"
          reasons_json='[]'
          status="ok"
          source_run_id=""
          source_head_sha=""
          runs_total=0
          runs_with_failures=0
          latest_failed_samples=0
          latest_persist_total_avg="null"
          previous_persist_total_avg="null"
          persist_total_avg_delta="null"
          latest_dropped_nodes_max="null"
          previous_dropped_nodes_max="null"
          dropped_nodes_max_delta="null"
          history_summary_file=""

          add_reason() {
            local reason="$1"
            reasons_json="$(jq -c --arg reason "${reason}" '. + [$reason]' <<<"${reasons_json}")"
          }

          if latest_runs_json="$(gh run list --workflow "Backend Parity Smoke" --branch main --limit 20 --json databaseId,conclusion,headSha,createdAt 2>/tmp/core_gate_backend_parity_history_gh_list.err)"; then
            source_run_id="$(jq -r '[.[] | select(.conclusion=="success")] | first | .databaseId // empty' <<<"${latest_runs_json}")"
            source_head_sha="$(jq -r '[.[] | select(.conclusion=="success")] | first | .headSha // empty' <<<"${latest_runs_json}")"
          else
            add_reason "gh_run_list_failed"
          fi

          if [[ -z "${source_run_id}" ]]; then
            add_reason "no_successful_backend_parity_run_found"
          else
            dl_dir="$(mktemp -d)"
            if gh run download "${source_run_id}" -n backend-parity-rollup -D "${dl_dir}" >/tmp/core_gate_backend_parity_history_gh_download.log 2>&1; then
              history_summary_file="$(find "${dl_dir}" -type f -path '*/history/summary.json' | head -n 1 || true)"
              if [[ -n "${history_summary_file}" && -f "${history_summary_file}" ]]; then
                cp "${history_summary_file}" "${out_dir}/history_summary_run_${source_run_id}.json"
                runs_total="$(jq -r '.runs_total // 0' "${history_summary_file}")"
                runs_with_failures="$(jq -r '.runs_with_failures // 0' "${history_summary_file}")"
                latest_failed_samples="$(jq -r '.latest.failed_samples // 0' "${history_summary_file}")"
                latest_persist_total_avg="$(jq -r '.latest.persist_total_avg // "null"' "${history_summary_file}")"
                previous_persist_total_avg="$(jq -r 'if (.series | length) >= 2 then (.series[-2].persist_total_avg // "null") else "null" end' "${history_summary_file}")"
                persist_total_avg_delta="$(jq -r '
                  def num_or_null(v): if (v | type) == "number" then v else null end;
                  if (.series | length) >= 2 then
                    (num_or_null(.latest.persist_total_avg) as $l
                      | num_or_null(.series[-2].persist_total_avg) as $p
                      | if ($l != null and $p != null) then ($l - $p) else null end)
                  else null end // "null"
                ' "${history_summary_file}")"
                latest_dropped_nodes_max="$(jq -r '.latest.dropped_nodes_max // "null"' "${history_summary_file}")"
                previous_dropped_nodes_max="$(jq -r 'if (.series | length) >= 2 then (.series[-2].dropped_nodes_max // "null") else "null" end' "${history_summary_file}")"
                dropped_nodes_max_delta="$(jq -r '
                  def num_or_null(v): if (v | type) == "number" then v else null end;
                  if (.series | length) >= 2 then
                    (num_or_null(.latest.dropped_nodes_max) as $l
                      | num_or_null(.series[-2].dropped_nodes_max) as $p
                      | if ($l != null and $p != null) then ($l - $p) else null end)
                  else null end // "null"
                ' "${history_summary_file}")"
              else
                add_reason "history_summary_missing_in_backend_parity_rollup_artifact"
              fi
            else
              add_reason "gh_run_download_backend_parity_rollup_failed"
            fi
            rm -rf "${dl_dir}" || true
          fi

          if [[ "${runs_total}" -lt "${min_runs}" ]]; then
            add_reason "runs_total_below_min_threshold"
          fi
          if [[ "${runs_with_failures}" -gt "${max_failed_runs}" ]]; then
            add_reason "runs_with_failures_above_threshold"
          fi
          if [[ "${latest_failed_samples}" -gt "${max_latest_failed_samples}" ]]; then
            add_reason "latest_failed_samples_above_threshold"
          fi

          compare_float_gt() {
            local left="$1"
            local right="$2"
            awk -v a="${left}" -v b="${right}" 'BEGIN { exit !(a>b) }'
          }

          if [[ "${persist_total_avg_delta}" != "null" ]] && compare_float_gt "${persist_total_avg_delta}" "${max_persist_total_avg_delta}"; then
            add_reason "persist_total_avg_delta_above_threshold"
          fi
          if [[ "${dropped_nodes_max_delta}" != "null" ]] && compare_float_gt "${dropped_nodes_max_delta}" "${max_dropped_nodes_max_delta}"; then
            add_reason "dropped_nodes_max_delta_above_threshold"
          fi

          reasons_count="$(jq 'length' <<<"${reasons_json}")"
          if [[ "${reasons_count}" -gt 0 ]]; then
            status="warn"
            if [[ "${enforce}" == "true" ]]; then
              status="fail"
            fi
          fi

          jq -n \
            --arg status "${status}" \
            --argjson enforce "${enforce}" \
            --arg source_run_id "${source_run_id}" \
            --arg source_head_sha "${source_head_sha}" \
            --argjson runs_total "${runs_total}" \
            --argjson runs_with_failures "${runs_with_failures}" \
            --argjson latest_failed_samples "${latest_failed_samples}" \
            --argjson min_runs "${min_runs}" \
            --argjson max_failed_runs "${max_failed_runs}" \
            --argjson max_latest_failed_samples "${max_latest_failed_samples}" \
            --argjson max_persist_total_avg_delta "${max_persist_total_avg_delta}" \
            --argjson max_dropped_nodes_max_delta "${max_dropped_nodes_max_delta}" \
            --argjson reasons "${reasons_json}" \
            --arg latest_persist_total_avg "${latest_persist_total_avg}" \
            --arg previous_persist_total_avg "${previous_persist_total_avg}" \
            --arg persist_total_avg_delta "${persist_total_avg_delta}" \
            --arg latest_dropped_nodes_max "${latest_dropped_nodes_max}" \
            --arg previous_dropped_nodes_max "${previous_dropped_nodes_max}" \
            --arg dropped_nodes_max_delta "${dropped_nodes_max_delta}" \
            '{
              status: $status,
              enforce: $enforce,
              source_run_id: (if $source_run_id == "" then null else $source_run_id end),
              source_head_sha: (if $source_head_sha == "" then null else $source_head_sha end),
              thresholds: {
                min_runs: $min_runs,
                max_failed_runs: $max_failed_runs,
                max_latest_failed_samples: $max_latest_failed_samples,
                max_persist_total_avg_delta: $max_persist_total_avg_delta,
                max_dropped_nodes_max_delta: $max_dropped_nodes_max_delta
              },
              observed: {
                runs_total: $runs_total,
                runs_with_failures: $runs_with_failures,
                latest_failed_samples: $latest_failed_samples,
                latest_persist_total_avg: (if $latest_persist_total_avg == "null" then null else ($latest_persist_total_avg | tonumber) end),
                previous_persist_total_avg: (if $previous_persist_total_avg == "null" then null else ($previous_persist_total_avg | tonumber) end),
                persist_total_avg_delta: (if $persist_total_avg_delta == "null" then null else ($persist_total_avg_delta | tonumber) end),
                latest_dropped_nodes_max: (if $latest_dropped_nodes_max == "null" then null else ($latest_dropped_nodes_max | tonumber) end),
                previous_dropped_nodes_max: (if $previous_dropped_nodes_max == "null" then null else ($previous_dropped_nodes_max | tonumber) end),
                dropped_nodes_max_delta: (if $dropped_nodes_max_delta == "null" then null else ($dropped_nodes_max_delta | tonumber) end)
              },
              reasons: $reasons
            }' > "${check_file}"

          cat "${check_file}"

          if [[ "${status}" == "fail" ]]; then
            echo "backend parity telemetry history thresholds violated in enforce mode" >&2
            exit 1
          fi

      - name: Publish summary
        if: always()
        shell: bash
        run: |
          set -euo pipefail
          summary_file="$(find artifacts/core_gate -type f -name summary.json | sort | tail -n 1 || true)"
          governance_summary_file="$(find artifacts/governance -type f -name summary.json | sort | tail -n 1 || true)"
          backend_parity_history_check_file="artifacts/core_gate/backend_parity_history/check.json"
          backend_parity_history_summary_file="$(find artifacts/core_gate/backend_parity_history -type f -name 'history_summary_run_*.json' | sort | tail -n 1 || true)"
          {
            echo "## Core Production Gate"
            echo
            if [[ -n "${summary_file}" && -f "${summary_file}" ]]; then
              echo "summary: \`${summary_file}\`"
              echo
              jq '.' "${summary_file}"
            else
              echo "summary not found"
            fi
            echo
            echo "## Governance Weekly Report Gate"
            echo
            if [[ -n "${governance_summary_file}" && -f "${governance_summary_file}" ]]; then
              echo "summary: \`${governance_summary_file}\`"
              echo
              jq '.' "${governance_summary_file}"
            else
              echo "summary not found"
            fi
            echo
            echo "## Backend Parity Telemetry History"
            echo
            if [[ -f "${backend_parity_history_check_file}" ]]; then
              echo "check: \`${backend_parity_history_check_file}\`"
              echo
              jq '.' "${backend_parity_history_check_file}"
            else
              echo "check not found"
            fi
            echo
            if [[ -n "${backend_parity_history_summary_file}" && -f "${backend_parity_history_summary_file}" ]]; then
              echo "history summary: \`${backend_parity_history_summary_file}\`"
              echo
              jq '{ok, runs_total, runs_with_failures, latest, stats, failed_runs}' "${backend_parity_history_summary_file}"
            else
              echo "history summary not found"
            fi
          } >> "${GITHUB_STEP_SUMMARY}"

      - name: Upload artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: core-production-gate-artifacts
          path: |
            artifacts/core_gate/
            artifacts/governance/
          retention-days: 14
          if-no-files-found: warn

      - name: Capture diagnostics on failure
        if: failure()
        shell: bash
        run: |
          set +e
          mkdir -p /tmp/core_gate_diag
          cp /tmp/core_gate_capability_api_probe.json /tmp/core_gate_diag/capability_api_probe.json 2>/dev/null || true
          cp /tmp/core_gate_policy_planner_probe.json /tmp/core_gate_diag/policy_planner_api_probe.json 2>/dev/null || true
          cp artifacts/core_gate/backend_parity_history/check.json /tmp/core_gate_diag/backend_parity_history_check.json 2>/dev/null || true
          cp artifacts/core_gate/backend_parity_history/history_summary_run_*.json /tmp/core_gate_diag/ 2>/dev/null || true
          find artifacts/core_gate -type f -maxdepth 3 2>/dev/null | sort > /tmp/core_gate_diag/files.txt || true
          summary_file="$(find artifacts/core_gate -type f -name summary.json | sort | tail -n 1 || true)"
          if [[ -n "${summary_file}" && -f "${summary_file}" ]]; then
            jq '{ok, fail_reasons, steps}' "${summary_file}" > /tmp/core_gate_diag/summary_excerpt.json || true
          fi
          docker compose ps > /tmp/core_gate_diag/compose_ps.txt || true
          docker compose logs --no-color > /tmp/core_gate_diag/compose_logs.txt || true

      - name: Upload diagnostics
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: core-production-gate-diagnostics
          path: /tmp/core_gate_diag/
          retention-days: 14
          if-no-files-found: warn

      - name: Stop stack
        if: always()
        shell: bash
        run: |
          set +e
          if [[ -f docker-compose.yml ]]; then
            docker compose down -v
          else
            echo "docker-compose.yml not found, skip compose down"
          fi
